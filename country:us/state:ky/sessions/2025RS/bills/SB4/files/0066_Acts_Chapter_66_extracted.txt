Title: AN ACT relating to protection of information and declaring an emergency.
Official Title: AN ACT relating to protection of information and declaring an emergency.
Number of Sections: 68
Source: versions - Acts Chapter 66
Media Type: application/pdf
Strikethrough Detection: 11 sections found

================================================================================

Section 1:
CHAPTER 66 1
CHAPTER 66
( SB 4 )
Be it enacted by the General Assembly of the Commonwealth of Kentucky:
Section 1. KRS 42.722 is amended to read as follows:
As used in KRS 42.720 to 42.742:
(1) "Artificial intelligence" means the use of machine learning and related technologies that uses data to train
statistical models for the purpose of enabling computer systems to perform tasks normally associated with
human intelligence or perception;
(2) "Artificial intelligence system":
(a) Means any machine-based computing system that, for any explicit or implicit objective, infers from
the inputs such system receives how to generate outputs, including but not limited to content,
decisions, predictions, or recommendations, that can influence physical or virtual environments; and
(b) Does not include an artificial intelligence system that is used for development, prototyping, and
research activities before such artificial intelligence system;
(3) "Communications" or "telecommunications" means any transmission, emission, or reception of signs, signals,
writings, images, and sounds of intelligence of any nature by wire, radio, optical, or other electromagnetic
systems, and includes all facilities and equipment performing these functions;
(4) "Consequential decision" means any decision that has a material legal or similarly significant effect on the
provision or denial of services, cost, or terms to any citizen or business;
(5) "Deployer" means any state department, state agency, or state administrative body in the Commonwealth
that puts into use a high-risk artificial intelligence system;
(6) "Developer" means any department, agency, or administrative body that develops or intentionally and
substantially modifies a high-risk artificial intelligence system that is offered, purchased, sold, leased,
given, or otherwise provided to citizens and businesses in the Commonwealth;
(7) "Foundation model" means a machine learning model that is trained on broad data at scale, designed for
generality of output, and can be adapted to a wide range of distinctive tasks;
(8) "General-purpose artificial intelligence model":
(a) Means a model used by any form of artificial intelligence system that displays significant generality,
is capable of performing a wide range of distinct tasks, and can be integrated into a variety of
subsequent applications or systems; and
(b) Does not include any artificial intelligence model that is used for development, prototyping, and
research activities before such artificial intelligence model is released on the market;
(9) "Generative artificial intelligence" means an artificial intelligence system that is capable of producing and
used to produce synthetic content, including audio, images, text, and videos;
(10) "Generative artificial intelligence system" means any artificial intelligence system or service that
incorporates generative artificial intelligence;
(11)[(2)] "Geographic information system" or "GIS" means a computerized database management system for the
capture, storage, retrieval, analysis, and display of spatial or locationally defined data;
(12) "High-risk artificial intelligence system":
(a) Means any artificial intelligence system that is a substantial factor in the decision-making process or
specifically intended to autonomously make, or be a substantial factor in making, a consequential
decision; and
(b) Does not include a system or service intended to perform a narrow procedural task, improve the
result of a completed human activity, or detect decision-making patterns or deviations from previous
Legislative Research Commission PDF Version
2 ACTS OF THE GENERAL ASSEMBLY
decision-making patterns and is not meant to replace or influence human assessment without human
review, or perform a preparatory task in an assessment relevant to a consequential decision;
(13)[(3)] "Information resources" means the procedures, equipment, and software that are designed, built,
operated, and maintained to collect, record, process, store, retrieve, display, and transmit information, and
associated personnel;
(14)[(4)] "Information technology" means data processing and telecommunications hardware, software, services,
supplies, facilities, maintenance, and training that are used to support information processing and
telecommunications systems to include geographic information systems;
(15) "Machine learning" means the development of algorithms to build data-derived statistical models that are
capable of drawing inferences from previously unseen data without explicit human instruction;
(16)[(5)] "Personal information" has the same meaning as in KRS 61.931;
(17)[(6)] "Project" means a program to provide information technologies support to functions within an executive
branch state agency, which should be characterized by well-defined parameters, specific objectives, common
benefits, planned activities, expected outcomes and completion dates, and an established budget with a
specified source of funding;
(18)[(7)] "Security breach" has the same meaning as in KRS 61.931; and
(19)[(8)] "Technology infrastructure" means any computing equipment, servers, networks, storage, desktop
support, telephony, enterprise shared systems, information technology security, disaster recovery, business
continuity, database administration, and software licensing.
Section 2. KRS 42.726 is amended to read as follows:
(1) The Commonwealth Office of Technology shall be the lead organizational entity within the executive branch
regarding delivery of information technology services, including application development and delivery, and
shall serve as the single information technology authority for the Commonwealth.
(2) The roles and duties of the Commonwealth Office of Technology shall include but not be limited to:
(a) Providing technical support and services to all executive agencies of state government in the application
of information technology;
(b) Assuring compatibility and connectivity of Kentucky's information systems;
(c) Developing strategies and policies to support and promote the effective applications of information
technology within state government as a means of saving money, increasing employee productivity, and
improving state services to the public, including electronic public access to information of the
Commonwealth;
(d) Developing, implementing, and managing strategic information technology directions, standards, and
enterprise architecture, including implementing necessary management processes to ensure full
compliance with those directions, standards, and architecture;
(e) Promoting effective and efficient design and operation of all major information resources management
processes for executive branch agencies, including improvements to work processes;
(f) Developing, implementing, and maintaining the technology infrastructure of the Commonwealth and all
related support staff, planning, administration, asset management, and procurement for all executive
branch cabinets and agencies except:

Section 2:
1. Agencies led by a statewide elected official;

Section 3:
2. The nine (9) public institutions of postsecondary education;

Section 4:
3. The Department of Education's services provided to local school districts;

Section 5:
4. The Kentucky Retirement Systems, the County Employees Retirement System, the Kentucky
Public Pensions Authority, and the Teachers' Retirement System;

Section 6:
5. The Kentucky Housing Corporation;

Section 7:
6. The Kentucky Lottery Corporation;

Section 8:
7. The Kentucky Higher Education Student Loan Corporation; and
CHAPTER 66 3

Section 9:
8. The Kentucky Higher Education Assistance Authority;
(g) Facilitating and fostering applied research in emerging technologies that offer the Commonwealth
innovative business solutions;
(h) Reviewing and overseeing large or complex information technology projects and systems for
compliance with statewide strategies, policies, and standards, including alignment with the
Commonwealth's business goals, investment, and other risk management policies. The executive
director is authorized to grant or withhold approval to initiate these projects;
(i) Integrating information technology resources to provide effective and supportable information
technology applications in the Commonwealth;
(j) Establishing the central statewide geographic information clearinghouse to maintain map inventories,
information on current and planned geographic information systems applications, information on grants
available for the acquisition or enhancement of geographic information resources, and a directory of
geographic information resources available within the state or from the federal government;
(k) Coordinating multiagency information technology projects, including overseeing the development and
maintenance of statewide base maps and geographic information systems;
(l) Providing access to both consulting and technical assistance, and education and training, on the
application and use of information technologies to state and local agencies;
(m) In cooperation with other agencies, evaluating, participating in pilot studies, and making
recommendations on information technology hardware and software;
(n) Providing staff support and technical assistance to the Geographic Information Advisory Council and
the Kentucky Information Technology Advisory Council;
(o) Overseeing the development of a statewide geographic information plan with input from the
Geographic Information Advisory Council;
(p) Developing for state executive branch agencies a coordinated security framework and model
governance structure relating to the privacy and confidentiality of personal information collected and
stored by state executive branch agencies, including but not limited to:

Section 10:
1. Identification of key infrastructure components and how to secure them;

Section 11:
2. Establishment of a common benchmark that measures the effectiveness of security, including
continuous monitoring and automation of defenses;

Section 12:
3. Implementation of vulnerability scanning and other security assessments;

Section 13:
4. Provision of training, orientation programs, and other communications that increase awareness of
the importance of security among agency employees responsible for personal information; and

Section 14:
5. Development of and making available a cyber security incident response plan and procedure;[
and]
(q) Establishing, publishing, maintaining, and implementing comprehensive policy standards and
procedures for the responsible, ethical, and transparent use of generative artificial intelligence
systems and high-risk artificial intelligence systems by departments, agencies, and administrative
bodies, including but not limited to policy standards and procedures that:

Section 15:
1. Govern their procurement, implementation, and ongoing assessment;

Section 16:
2. Address and provide resources for security of data and privacy; and

Section 17:
3. Create guidelines for acceptable use policies for integrating high-risk artificial intelligence
systems; and
(r) Preparing proposed legislation and funding proposals for the General Assembly that will further solidify
coordination and expedite implementation of information technology systems.
(3) The Commonwealth Office of Technology may:
Legislative Research Commission PDF Version
4 ACTS OF THE GENERAL ASSEMBLY
(a) Provide general consulting services, technical training, and support for generic software applications,
upon request from a local government, if the executive director finds that the requested services can be
rendered within the established terms of the federally approved cost allocation plan;
(b) Promulgate administrative regulations in accordance with KRS Chapter 13A necessary for the
implementation of KRS 42.720 to 42.742, 45.253, 171.420, 186A.040, and 186A.285;
(c) Solicit, receive, and consider proposals from any state agency, federal agency, local government,
university, nonprofit organization, private person, or corporation;
(d) Solicit and accept money by grant, gift, donation, bequest, legislative appropriation, or other
conveyance to be held, used, and applied in accordance with KRS 42.720 to 42.742, 45.253, 171.420,
186A.040, and 186A.285;
(e) Make and enter into memoranda of agreement and contracts necessary or incidental to the performance
of duties and execution of its powers, including but not limited to agreements or contracts with the
United States, other state agencies, and any governmental subdivision of the Commonwealth;
(f) Accept grants from the United States government and its agencies and instrumentalities, and from any
source, other than any person, firm, or corporation, or any director, officer, or agent thereof that
manufactures or sells information resources technology equipment, goods, or services. To these ends,
the Commonwealth Office of Technology shall have the power to comply with those conditions and
execute those agreements that are necessary, convenient, or desirable; and
(g) Purchase interest in contractual services, rentals of all types, supplies, materials, equipment, and other
services to be used in the research and development of beneficial applications of information resources
technologies. Competitive bids may not be required for:

Section 18:
1. New and emerging technologies as approved by the executive director or her or his designee; or

Section 19:
2. Related professional, technical, or scientific services, but contracts shall be submitted in
accordance with KRS 45A.690 to 45A.725.
(4) Nothing in this section shall be construed to alter or diminish the provisions of KRS 171.410 to 171.740 or the
authority conveyed by these statutes to the Archives and Records Commission and the Department for
Libraries and Archives.
(5) The Commonwealth Office of Technology shall, on or before October 1 of each year, submit to the Legislative
Research Commission a report in accordance with KRS 57.390 detailing:
(a) Any security breaches that occurred within organizational units of the executive branch of state
government during the prior fiscal year that required notification to the Commonwealth Office of
Technology under KRS 61.932;
(b) Actions taken to resolve the security breach, and to prevent additional security breaches in the future;
(c) A general description of what actions are taken as a matter of course to protect personal data from
security breaches; and
(d) Any quantifiable financial impact to the agency reporting a security breach.
SECTION 3. A NEW SECTION OF KRS 42.720 TO 42.742 IS CREATED TO READ AS FOLLOWS:
(1) The Commonwealth Office of Technology shall create an Artificial Intelligence Governance Committee to
govern the use of artificial intelligence systems by state departments, state agencies, and state administrative
bodies by:
(a) Developing policy standards and guiding principles to mitigate risks and protect data and privacy of
Kentucky citizens and businesses that adhere to the latest version of Standard ISO/IEC 42001 of the
International Organization for Standardization;
(b) Establishing technology standards to provide protocols and requirements for the use of generative
artificial intelligence and high-risk artificial intelligence systems;
(c) Ensuring transparency in the use of artificial intelligence systems;
(d) Maintaining a centralized registry to include current inventory of generative artificial intelligence
systems and high-risk artificial intelligence systems; and
CHAPTER 66 5
(e) Developing an approval process to include a registry of application, use case, and decision rationale
aimed at mitigation of risks.
(2) The Artificial Intelligence Governance Committee shall develop policies and procedures to ensure that any
department, program, cabinet, agency, or administrative body that utilizes and accesses the
Commonwealth's information technology and technology infrastructure shall:
(a) Verify the use and development of generative artificial intelligence systems and high-risk artificial
intelligence systems; and
(b) Act in compliance with responsible, ethical, and transparent procedures to implement the use of
artificial intelligence technologies by:

Section 20:
1. Ensuring artificial intelligence models have comprehensive and complete documentation that
is available for review and inspection;

Section 21:
2. Requiring review and intervention by humans dependent on the use case and potential risk for
all outcomes from generative and high-risk artificial intelligence systems; and

Section 22:
3. Ensuring the use of generative artificial intelligence and high-risk artificial intelligence
systems are resilient, accountable, and explainable.
(3) The Commonwealth Office of Technology shall prioritize personal privacy and the protection of the data of
individuals and businesses as the state develops, implements, employs, and procures artificial intelligence
systems, generative artificial intelligence systems, and high-risk artificial intelligence systems by ensuring
all departments, agencies, and administrative bodies:
(a) Allow only the use of necessary data in artificial intelligence systems;
(b) Do not allow unrestricted access to personal data controlled by the Commonwealth; and
(c) Secure all data and implement a timeframe for data retention.
(4) To maintain and secure the technology infrastructure, information technology, information resources, and
personal information, all departments, agencies, and administrative bodies shall be subject to review of
generative artificial intelligence systems or high-risk artificial intelligence systems.
(5) At a minimum, the executive director of the Commonwealth Office of Technology shall consider and
document:
(a) How the artificial intelligence system will not result in unlawful discrimination against any
individual or group of individuals;
(b) How the use of generative artificial intelligence or other artificial intelligence capabilities will benefit
the citizens of the Commonwealth and serve the objectives of the department or agency;
(c) To what extent oversight and human interaction of the artificial intelligence system should be
required;
(d) The potential risks, including cybersecurity, data protection and privacy, and health and safety of
individuals and businesses, and a mitigation strategy to any identified or potential risk; and
(e) The proper control and management for all data possessed by the Commonwealth to maintain
security and data quality.
(6) (a) A department, agency, or administrative body shall disclose to the public, through a clear and
conspicuous disclaimer, when generative artificial intelligence, artificial intelligence systems, or
other artificial intelligence-related capabilities are used:

Section 23:
1. To render any decision regarding individual citizens or businesses within the state;

Section 24:
2. In any process, or to produce materials used by the system or humans, to inform a decision or
create an output; or

Section 25:
3. To produce information or outputs accessible by citizens and businesses.
(b) When an artificial intelligence system makes external decisions related to citizens of the
Commonwealth, a department, agency, or administrative body shall:
Legislative Research Commission PDF Version
6 ACTS OF THE GENERAL ASSEMBLY

Section 26:
1. Disclose how artificial intelligence is used in the decision-making process;

Section 27:
2. Provide the extent of human involvement in validating and oversight of any decision made;
and

Section 28:
3. Make readily available options for individuals to appeal a consequential decision that involves
artificial intelligence.
(c) Any disclaimer under paragraph (a) of this subsection shall also provide information regarding
third-party artificial intelligence products or programs, including but not limited to information as to
how the high-risk artificial intelligence system or generative artificial intelligence system works, such
as system cards or other documented information provided by developers.
(7) The Commonwealth Office of Technology shall establish policies to encompass legal and ethical
frameworks to ensure that any artificial intelligence systems shall align with existing laws, administrative
regulations, and guidelines, which shall be updated at least annually to maintain compliance as technology
and industry best practices evolve.
(8) (a) Operating standards for utilization of high-risk artificial intelligence systems shall prohibit the use of
a high-risk artificial intelligence system to render a consequential decision without the design and
implementation of a risk management policy and program for high-risk artificial intelligence
systems. The risk management policy shall:

Section 29:
1. Specify principles, process, and personnel that shall be utilized to maintain the risk
management program; and

Section 30:
2. Identify, mitigate, and document any bias or potential bias that is a potential consequence of
use in making a consequential decision.
(b) Each risk management policy designed and implemented shall at a minimum adhere to the latest
version of Standard ISO/IEC 42001 of the International Organization for Standardization, or
another national or internationally recognized risk management framework for artificial intelligence
systems, and consider the:

Section 31:
1. Size and complexity of the deployer;

Section 32:
2. Nature, scope, and intended use of the high-risk artificial intelligence system and its deployer;
and

Section 33:
3. Sensitivity and volume of data processed.
(9) Sections 1 to 3 of this Act shall not be construed to require the disclosure of trade secrets, confidential or
proprietary information about the design or use of an artificial intelligence system, or any information
which would create a security risk.
(10) The Commonwealth Office of Technology shall provide education and training of employees about the
benefits and risks of artificial intelligence and allowable use policies.
(11) (a) The Commonwealth Office of Technology shall transmit reports to the Legislative Research
Commission and the Interim Joint Committee on State Government by December 1, 2025, and
annually every year thereafter. The reports shall include:

Section 34:
1. The artificial intelligence registry, which shall include the current inventory and use case of
artificial intelligence utilized in state government;

Section 35:
2. Applications received for use of artificial intelligence, including the decision and rationale in
approving or disapproving a request in compliance with subsection (5)(c) of this section; and

Section 36:
3. Third-party artificial intelligence developers, system administrators, providers, and contractors
submitted for review in compliance with subsection (5) of this section.
(b) To facilitate the report in paragraph (a) of this subsection, the Commonwealth Office of Technology
shall receive from each department, agency, and administrative body a report examining and
identifying potential use cases for the deployment of generative artificial intelligence systems and
high-risk artificial intelligence systems, including a description of the benefits and risks to
individuals, communities, government, and government employees.
CHAPTER 66 7
(12) The Commonwealth Office of Technology shall promulgate administrative regulations in accordance with
KRS Chapter 13A to implement this section and Section 2 of this Act by December 1, 2025.
Section 4. KRS 117.001 is amended to read as follows:
As used in this chapter[, unless the context otherwise requires]:
(1) "Audit log" means a detailed record of all actions and events that have occurred on the voting system,
including:
(a) Log-in attempts with username and time stamp;
(b) Election definition and setup;
(c) Ballot preparation and results processing;
(d) Diagnostics of any type; and
(e) Error and warning messages and operator response;
(2) "Automatic tabulating equipment" means apparatus necessary to automatically examine and count votes as
designated on ballots and data processing machines which can be used for counting ballots and tabulating
results;
(3) "Ballot" or "official ballot" means the official presentation of offices and candidates to be voted for, including
write-in candidates, and all public questions submitted for determination, and shall include a voting machine
ballot, a paper ballot, an absentee ballot, a federal provisional ballot, a federal provisional absentee ballot, or a
supplemental paper ballot which has been authorized for the use of voters in any primary, regular election, or
special election by the Secretary of State or the county clerk;
(4) "Ballot box" means any box, bag, or other container that can be locked, sealed, or otherwise rendered tamper-
resistant, for receiving ballots;
(5) "Ballot marking device" means any approved device for marking a ballot which will enable the ballot to be
tabulated manually or by means of automatic tabulating equipment;
(6) "Election" or "elections" means any primary, regular election, or special election;
(7) "Election officer" has the same meaning as in KRS 118.015;
(8) (a) "Electioneering communication" means any communication broadcast by cable, internet, television,
or radio, presented on an electronic billboard, made in telephone calls to personal residences, or
otherwise electronically distributed that:

Section 37:
1. Unambiguously refers to any candidate for any state, county, city, or district office, or to any
ballot measure;

Section 38:
2. Is broadcast, printed, mailed, delivered, made, or distributed within forty-five (45) days before
a primary or regular election; and

Section 39:
3. Is broadcast to, distributed to, in telephone calls made to, or otherwise distributed to an
audience that includes members of the electorate for such public office or the electorate
associated with the ballot containing the ballot measure.
(b) "Electioneering communication" does not include:

Section 40:
1. Any news articles, editorial endorsements, opinions or commentary, writings, or letters to the
editor printed in a newspaper, magazine, or other periodical not owned or controlled by a
candidate, committee, or political party;

Section 41:
2. Any editorial endorsements or opinions aired by a broadcast facility not owned or controlled
by a candidate, committee, or political party;

Section 42:
3. Any communication by persons made in the regular course and scope of their business or any
communication made by a membership organization solely to members of such an
organization and their families;

Section 43:
4. Any communication that refers to any candidate only as part of the popular name of a bill or
statute;
Legislative Research Commission PDF Version
8 ACTS OF THE GENERAL ASSEMBLY

Section 44:
5. A communication that constitutes a contribution or independent expenditure as defined in
KRS 121.015; or

Section 45:
6. A bona fide newscast, news interview, news documentary, or on-the-spot coverage of a bona
fide news event broadcast on any radio or television broadcasting station, including a cable or
satellite television operator, programmer, or producer, that is not owned or controlled by a
candidate, committee, or political party, provided that the entity does not remove or modify any
disclaimer provided by the sponsor of the communication;
(9) "E-poll book" means an electronic device capable of holding a file of voter data and related information for
use in identifying registered voters prior to a voter's receiving or casting a ballot, and allowing a voter to
electronically sign in on an electronic registered voter roster in lieu of signing a paper registered voter roster;
(10)[(9)] "Federal provisional voter" means a person:
(a) Who does not appear to be registered to vote;
(b) Whose name does not appear on the precinct roster;
(c) Who has not provided proof of identification to the precinct election officer before voting in a federal
election; and
(d) Who elects to proceed with voting a federal provisional ballot under KRS 117.229;
(11)[(10)] "Federal provisional ballot" or "federal provisional absentee ballot" means ballots which have been
authorized by the Secretary of State or the county clerk to be used by federal provisional voters in any federal
primary or election;
(12)[(11)] "Information content provider" means any person or entity that is responsible, in whole or in part,
for the creation or development of information provided through the internet or any other interactive
computer service;
(13) "Inner envelope" or "secrecy envelope" means the envelope provided to the voter with a ballot into which the
voter shall place his or her voted ballot;
(14) "Interactive computer service":
(a)_ Means any information service, system, or access software provider that provides or enables
computer access by multiple users to a computer server, including specifically a service or system
that provides access to the internet and such services offered or systems operated by libraries or
educational institutions; and
(b) Does not include exemptions in the Communication Decency Act of 1996, as amended, 47 U.S.C. sec.
230;
(15)[(12)] "Political group" has the same meaning as in KRS 118.015;
(16)[(13)] "Political organization" has the same meaning as in KRS 118.015;
(17)[(14)] "Precinct ballot counter" means an automatic tabulating device used at the precinct to tabulate and
process ballots;
(18)[(15)] "Proof of identification" means a document that was issued by:
(a) The United States or the Commonwealth of Kentucky, and the document contains:

Section 46:
1. The name of the individual to whom the document was issued; and

Section 47:
2. A photograph of the individual to whom the document was issued;
(b) The United States Department of Defense, a branch of the uniformed services, the Merchant Marine, or
the Kentucky National Guard, and the document contains:

Section 48:
1. The name of the individual to whom the document was issued; and

Section 49:
2. A photograph of the individual to whom the document was issued;
(c) A public or private college, university, or postgraduate technical or professional school located within
the United States, and the document contains:

Section 50:
1. The name of the individual to whom the document was issued; and
CHAPTER 66 9

Section 51:
2. A photograph of the individual to whom the document was issued; or
(d) Any city government, county government, urban-county government, charter county government,
consolidated local government, or unified local government, which is located within this state, and the
document contains:

Section 52:
1. The name of the individual to whom the document was issued; and

Section 53:
2. A photograph of the individual to whom the document was issued;
(19) "Sponsor" means the person or entity paying for the electioneering communication. If a person or entity
acts as an agent for another or is reimbursed by another for the payment, the original source of the
payment is the sponsor;
(20) (a) 1. "Synthetic media" means an audio recording or video recording of an identifiable natural
individual's appearance, action, or speech that has been intentionally manipulated with the
use of generative adversarial network techniques in a manner to create a realistic but false
audio or video that produces:
a. A depiction that, to a reasonable individual, is of an identifiable natural individual in
appearance, action, or speech that did not actually occur in reality and that was created
without the consent of such individual; and
b. A fundamentally different understanding or impression of the appearance, action, or
speech than a reasonable person would have from the unaltered, original version of the
audio recording or video recording.

Section 54:
2. As used in this paragraph:
a. "Generative adversarial network" means a machine learning model that uses neural
networks to develop new data and make more accurate predictions; and
b. "Neural network" means a machine learning algorithm modeled on the human brain
and nervous system.
(b) "Synthetic media" does not include content that contains a disclosure under subsection (1) of

Section 55:
Section 5 of this Act.
(21)[(16)] "Voting booth" or "ballot completion area" means an area in which a voter casts his or her vote or
completes his or her ballot which is designed to ensure the secrecy of the vote;
(22)[(17)] "Vote center" means a consolidated precinct of the county;
(23)[(18)] "Voting equipment" means any physical component of a voting system and includes voting machines
where voting machines are in operation;
(24)[(19)] "Voting machine" or "machine":
(a) Means a part of a voting system that consists of one (1) or more electronic devices that operate
independently or as a combination of a ballot marking device and an electronic or automatic vote
tabulation device; and
(b) Does not include an e-poll book;
(25)[(20)] "Voting system":
(a) Means the total combination of physical, mechanical, electromechanical, or electronic equipment,
including the software, hardware, firmware, and documentation required to program, control, and
support that equipment, that is used to:

Section 56:
1. Define ballots;

Section 57:
2. Cast and count votes;

Section 58:
3. Report or display election results; and

Section 59:
4. Maintain and produce any audit trail information;
(b) Includes the practices and associated documentation used to:
Legislative Research Commission PDF Version
10 ACTS OF THE GENERAL ASSEMBLY

Section 60:
1. Identify system components and versions of those components;

Section 61:
2. Test the system during its development and maintenance;

Section 62:
3. Maintain records of system errors and defects;

Section 63:
4. Determine specific system changes to be made to a system after the initial qualification of the
system;

Section 64:
5. Make available any materials to the voter, such as notices, instructions, forms, or paper ballots;
and
(c) Does not include an e-poll book; and
(26)[(21)] "Voter-verified paper audit trail" means a contemporaneous paper record of a ballot printed for the
voter to confirm his or her votes before the voter casts his or her ballot that:
(a) Allows the voter to verify the voter's ballot choices before the casting of the voter's ballot;
(b) Is not retained by the voter;
(c) Does not contain individual voter information;
(d) Is produced on paper that is sturdy, clean, and resistant to degradation; and
(e) Is readable in a manner that makes the voter's ballot choices obvious to the voter or any person without
the use of computer or electronic code.
SECTION 5. A NEW SECTION OF KRS CHAPTER 117 IS CREATED TO READ AS FOLLOWS:
(1) (a) Any candidate for any elected office whose appearance, action, or speech is altered through the use
of synthetic media in an electioneering communication may seek injunctive or other equitable relief
against the sponsor of the electioneering communication requiring that the communication includes
a disclosure that is clear and conspicuous and included in, or alongside and associated with, the
content in a manner that is likely to be noticed by the user.
(b) The court may award a prevailing party reasonable attorney's fees and costs. This paragraph does
not limit or preclude a plaintiff from securing or recovering any other available remedy.
(2) In any action brought under subsection (1) of this section:
(a) The plaintiff shall:

Section 65:
1. File in Circuit Court of the county in which he or she resides; and

Section 66:
2. Bear the burden of establishing the use of synthetic media by clear and convincing evidence.
(b) The following shall not be liable except as provided in subsection (3) of this section:

Section 67:
1. The medium disseminating the electioneering communication; and

Section 68:
2. An advertising sales representative of such medium.
(3) Failure to comply with an order of the court to include the required disclosure herein shall be subject to the
penalties set for KRS 121.990(3) for violation of KRS 121.190(1).
(4) It is an affirmative defense for any action brought under subsection (1) of this section that the
electioneering communication containing synthetic media includes a disclosure that is clear and
conspicuous and included in, or alongside and associated with, the content in a manner that is likely to be
noticed by the user.
(5) Except when a licensee, programmer, or operator of a federally licensed broadcasting station transmits an
electioneering communication that is subject to 47 U.S.C. sec. 315, a medium or its advertising sales
representative may be held liable in a cause of action brought under subsection (1) of this section if:
(a) The person intentionally removes any disclosure described in subsection (4) of this section from the
electioneering communication it disseminates and does not remove the electioneering
communication or replace the disclosure when notified; or
(b) Subject to affirmative defenses described in subsection (4) of this section, the person changes the
content of an electioneering communication in a manner that results in it qualifying as synthetic
media.
CHAPTER 66 11
(6) (a) A provider or user of an interactive computer service shall not be treated as the publisher or speaker
of any information provided by another information content provider.
(b) An interactive computer service may be held liable in accordance with subsection (3) of this section.
(c) An interactive computer service shall be exempt as provided by the Communications and Decency
Act of 1996, as amended, 47 U.S.C. sec. 230.
(7) Courts are encouraged to determine matters under this section expediently.
Section 6. Whereas implementing governance to maximize the opportunities for the responsible and
ethical use of artificial intelligence is vitally important to combat the critical impact artificial intelligence can have on
the security of data and information in the Commonwealth and it is critically important to protect candidates and
election officers from fraudulent misrepresentations of themselves and their issues, an emergency is declared to exist,
and this Act takes effect upon its passage and approval by the Governor or upon its otherwise becoming a law.
Signed by Governor March 24, 2025.
Legislative Research Commission PDF Version
[DELETED:  " " M i s s r h t g o i b n l t c D n i a a i s t i u f d a " " " " m a d a o a b t d o i a m a h a i s t i o p s l " " M c o p a r o d t a c i i a v o D " " a i s m a a i s o s t " " M D]
[DELETED:  " r m t p e a s t a d b " f m a t t a u t s i p a " " " p a e o a c d a a e b w a " " i m a c e s n s d T T P A D s s t t p i e p a t i o t D a i i n m p t e f P D A T T T T T T]
[DELETED:  T F a f a r i e t t o t C R a o l o c i t p a s f w s s p a s i a w t b g i a o r m p T e I i t r t p e a s i E C P a t b c a t a a e a t o t I c w o a e p i p s a m P O t d o a s g i p w i f t D f s e b a a c s f a m I E I P D E p m a i c p s a f t r e a t u o g a i G A C P T]
[DELETED:  P P a r i a w K C 1 n f t S r a c p f a s a f a l g S a a m b g g d b l a o o M A o t a p f o c o a d o o a t t P N R p t o s s b c s b s i N c b t s t t A a R C a t D f T A s b t o w o u o t e b o s d t p f y t r n t t C O o A A A T D E E M]
[DELETED:  D T p c a o a b t u a a t V A E R E t u o g a i a h a i T A D S T A a m t e d o t C O o T s c a H t a i s w n r i u d a a H T w e o a h i o t a i s s b T T p c a m f a d p b t C t m ( A d a o a b s d t t p t a c a d w g a i a i s o T I T W a a i s m e d r t c o t]
[DELETED:  D P M A d u p ( o t s s a p i r T C O o T s e p t e l a e ( O o a r m p a p f h a i S p p a p t s b u t m t r I E o S I 4 o t I O f S o S N S S T ( T C O o T s t r t t L R a t I J C o S G b D 1 2 a T A T T r f e d a a a b a r e a a i s i a d o t b a r t]
[DELETED:  T " l m a d r o a a a e t h o o t v s L E B D E " " " " " " ( " U I I b t d t i t c m t o o d t a t i m o t e f s p o o t e " A A A m b a m o s t m o s a A]
[DELETED:  A A " " W W W W " " t c o d o i p t t i o a o i " " M a i s s o a s p t p o e D " " " " T T A T T A A T]
[DELETED:  A A c g c g u g c c g T A " a a a f a o i r b a f t p t o s o t ( 1 " A A A " " " m d n i c t c a d u s ( o " " " " M a p o a v s t c o o ( o m e d t o D " M t t c o p m e o e e t s h f a d r t p c a D C R M I]
[DELETED:  I T M D M D " A I D I I ( A T I T F B T T A F I i a a d f a a b u s ( o t s t t c c s m i a d t i c a E c t i s t 4 U s 3 a m o i a s T c i d a d n r t e S]
[DELETED:  ( A A A C 6   W i g t m t o f r a]


================================================================================

Raw Text:
CHAPTER 66 1
CHAPTER 66
( SB 4 )
AN ACT relating to protection of information and declaring an emergency.
Be it enacted by the General Assembly of the Commonwealth of Kentucky:
Section 1. KRS 42.722 is amended to read as follows:
As used in KRS 42.720 to 42.742:
(1) "Artificial intelligence" means the use of machine learning and related technologies that uses data to train
statistical models for the purpose of enabling computer systems to perform tasks normally associated with
human intelligence or perception;
(2) "Artificial intelligence system":
(a) Means any machine-based computing system that, for any explicit or implicit objective, infers from
the inputs such system receives how to generate outputs, including but not limited to content,
decisions, predictions, or recommendations, that can influence physical or virtual environments; and
(b) Does not include an artificial intelligence system that is used for development, prototyping, and
research activities before such artificial intelligence system;
(3) "Communications" or "telecommunications" means any transmission, emission, or reception of signs, signals,
writings, images, and sounds of intelligence of any nature by wire, radio, optical, or other electromagnetic
systems, and includes all facilities and equipment performing these functions;
(4) "Consequential decision" means any decision that has a material legal or similarly significant effect on the
provision or denial of services, cost, or terms to any citizen or business;
(5) "Deployer" means any state department, state agency, or state administrative body in the Commonwealth
that puts into use a high-risk artificial intelligence system;
(6) "Developer" means any department, agency, or administrative body that develops or intentionally and
substantially modifies a high-risk artificial intelligence system that is offered, purchased, sold, leased,
given, or otherwise provided to citizens and businesses in the Commonwealth;
(7) "Foundation model" means a machine learning model that is trained on broad data at scale, designed for
generality of output, and can be adapted to a wide range of distinctive tasks;
(8) "General-purpose artificial intelligence model":
(a) Means a model used by any form of artificial intelligence system that displays significant generality,
is capable of performing a wide range of distinct tasks, and can be integrated into a variety of
subsequent applications or systems; and
(b) Does not include any artificial intelligence model that is used for development, prototyping, and
research activities before such artificial intelligence model is released on the market;
(9) "Generative artificial intelligence" means an artificial intelligence system that is capable of producing and
used to produce synthetic content, including audio, images, text, and videos;
(10) "Generative artificial intelligence system" means any artificial intelligence system or service that
incorporates generative artificial intelligence;
(11)[(2)] "Geographic information system" or "GIS" means a computerized database management system for the
capture, storage, retrieval, analysis, and display of spatial or locationally defined data;
(12) "High-risk artificial intelligence system":
(a) Means any artificial intelligence system that is a substantial factor in the decision-making process or
specifically intended to autonomously make, or be a substantial factor in making, a consequential
decision; and
(b) Does not include a system or service intended to perform a narrow procedural task, improve the
result of a completed human activity, or detect decision-making patterns or deviations from previous
Legislative Research Commission PDF Version

2 ACTS OF THE GENERAL ASSEMBLY
decision-making patterns and is not meant to replace or influence human assessment without human
review, or perform a preparatory task in an assessment relevant to a consequential decision;
(13)[(3)] "Information resources" means the procedures, equipment, and software that are designed, built,
operated, and maintained to collect, record, process, store, retrieve, display, and transmit information, and
associated personnel;
(14)[(4)] "Information technology" means data processing and telecommunications hardware, software, services,
supplies, facilities, maintenance, and training that are used to support information processing and
telecommunications systems to include geographic information systems;
(15) "Machine learning" means the development of algorithms to build data-derived statistical models that are
capable of drawing inferences from previously unseen data without explicit human instruction;
(16)[(5)] "Personal information" has the same meaning as in KRS 61.931;
(17)[(6)] "Project" means a program to provide information technologies support to functions within an executive
branch state agency, which should be characterized by well-defined parameters, specific objectives, common
benefits, planned activities, expected outcomes and completion dates, and an established budget with a
specified source of funding;
(18)[(7)] "Security breach" has the same meaning as in KRS 61.931; and
(19)[(8)] "Technology infrastructure" means any computing equipment, servers, networks, storage, desktop
support, telephony, enterprise shared systems, information technology security, disaster recovery, business
continuity, database administration, and software licensing.
Section 2. KRS 42.726 is amended to read as follows:
(1) The Commonwealth Office of Technology shall be the lead organizational entity within the executive branch
regarding delivery of information technology services, including application development and delivery, and
shall serve as the single information technology authority for the Commonwealth.
(2) The roles and duties of the Commonwealth Office of Technology shall include but not be limited to:
(a) Providing technical support and services to all executive agencies of state government in the application
of information technology;
(b) Assuring compatibility and connectivity of Kentucky's information systems;
(c) Developing strategies and policies to support and promote the effective applications of information
technology within state government as a means of saving money, increasing employee productivity, and
improving state services to the public, including electronic public access to information of the
Commonwealth;
(d) Developing, implementing, and managing strategic information technology directions, standards, and
enterprise architecture, including implementing necessary management processes to ensure full
compliance with those directions, standards, and architecture;
(e) Promoting effective and efficient design and operation of all major information resources management
processes for executive branch agencies, including improvements to work processes;
(f) Developing, implementing, and maintaining the technology infrastructure of the Commonwealth and all
related support staff, planning, administration, asset management, and procurement for all executive
branch cabinets and agencies except:
1. Agencies led by a statewide elected official;
2. The nine (9) public institutions of postsecondary education;
3. The Department of Education's services provided to local school districts;
4. The Kentucky Retirement Systems, the County Employees Retirement System, the Kentucky
Public Pensions Authority, and the Teachers' Retirement System;
5. The Kentucky Housing Corporation;
6. The Kentucky Lottery Corporation;
7. The Kentucky Higher Education Student Loan Corporation; and

CHAPTER 66 3
8. The Kentucky Higher Education Assistance Authority;
(g) Facilitating and fostering applied research in emerging technologies that offer the Commonwealth
innovative business solutions;
(h) Reviewing and overseeing large or complex information technology projects and systems for
compliance with statewide strategies, policies, and standards, including alignment with the
Commonwealth's business goals, investment, and other risk management policies. The executive
director is authorized to grant or withhold approval to initiate these projects;
(i) Integrating information technology resources to provide effective and supportable information
technology applications in the Commonwealth;
(j) Establishing the central statewide geographic information clearinghouse to maintain map inventories,
information on current and planned geographic information systems applications, information on grants
available for the acquisition or enhancement of geographic information resources, and a directory of
geographic information resources available within the state or from the federal government;
(k) Coordinating multiagency information technology projects, including overseeing the development and
maintenance of statewide base maps and geographic information systems;
(l) Providing access to both consulting and technical assistance, and education and training, on the
application and use of information technologies to state and local agencies;
(m) In cooperation with other agencies, evaluating, participating in pilot studies, and making
recommendations on information technology hardware and software;
(n) Providing staff support and technical assistance to the Geographic Information Advisory Council and
the Kentucky Information Technology Advisory Council;
(o) Overseeing the development of a statewide geographic information plan with input from the
Geographic Information Advisory Council;
(p) Developing for state executive branch agencies a coordinated security framework and model
governance structure relating to the privacy and confidentiality of personal information collected and
stored by state executive branch agencies, including but not limited to:
1. Identification of key infrastructure components and how to secure them;
2. Establishment of a common benchmark that measures the effectiveness of security, including
continuous monitoring and automation of defenses;
3. Implementation of vulnerability scanning and other security assessments;
4. Provision of training, orientation programs, and other communications that increase awareness of
the importance of security among agency employees responsible for personal information; and
5. Development of and making available a cyber security incident response plan and procedure;[
and]
(q) Establishing, publishing, maintaining, and implementing comprehensive policy standards and
procedures for the responsible, ethical, and transparent use of generative artificial intelligence
systems and high-risk artificial intelligence systems by departments, agencies, and administrative
bodies, including but not limited to policy standards and procedures that:
1. Govern their procurement, implementation, and ongoing assessment;
2. Address and provide resources for security of data and privacy; and
3. Create guidelines for acceptable use policies for integrating high-risk artificial intelligence
systems; and
(r) Preparing proposed legislation and funding proposals for the General Assembly that will further solidify
coordination and expedite implementation of information technology systems.
(3) The Commonwealth Office of Technology may:
Legislative Research Commission PDF Version

4 ACTS OF THE GENERAL ASSEMBLY
(a) Provide general consulting services, technical training, and support for generic software applications,
upon request from a local government, if the executive director finds that the requested services can be
rendered within the established terms of the federally approved cost allocation plan;
(b) Promulgate administrative regulations in accordance with KRS Chapter 13A necessary for the
implementation of KRS 42.720 to 42.742, 45.253, 171.420, 186A.040, and 186A.285;
(c) Solicit, receive, and consider proposals from any state agency, federal agency, local government,
university, nonprofit organization, private person, or corporation;
(d) Solicit and accept money by grant, gift, donation, bequest, legislative appropriation, or other
conveyance to be held, used, and applied in accordance with KRS 42.720 to 42.742, 45.253, 171.420,
186A.040, and 186A.285;
(e) Make and enter into memoranda of agreement and contracts necessary or incidental to the performance
of duties and execution of its powers, including but not limited to agreements or contracts with the
United States, other state agencies, and any governmental subdivision of the Commonwealth;
(f) Accept grants from the United States government and its agencies and instrumentalities, and from any
source, other than any person, firm, or corporation, or any director, officer, or agent thereof that
manufactures or sells information resources technology equipment, goods, or services. To these ends,
the Commonwealth Office of Technology shall have the power to comply with those conditions and
execute those agreements that are necessary, convenient, or desirable; and
(g) Purchase interest in contractual services, rentals of all types, supplies, materials, equipment, and other
services to be used in the research and development of beneficial applications of information resources
technologies. Competitive bids may not be required for:
1. New and emerging technologies as approved by the executive director or her or his designee; or
2. Related professional, technical, or scientific services, but contracts shall be submitted in
accordance with KRS 45A.690 to 45A.725.
(4) Nothing in this section shall be construed to alter or diminish the provisions of KRS 171.410 to 171.740 or the
authority conveyed by these statutes to the Archives and Records Commission and the Department for
Libraries and Archives.
(5) The Commonwealth Office of Technology shall, on or before October 1 of each year, submit to the Legislative
Research Commission a report in accordance with KRS 57.390 detailing:
(a) Any security breaches that occurred within organizational units of the executive branch of state
government during the prior fiscal year that required notification to the Commonwealth Office of
Technology under KRS 61.932;
(b) Actions taken to resolve the security breach, and to prevent additional security breaches in the future;
(c) A general description of what actions are taken as a matter of course to protect personal data from
security breaches; and
(d) Any quantifiable financial impact to the agency reporting a security breach.
SECTION 3. A NEW SECTION OF KRS 42.720 TO 42.742 IS CREATED TO READ AS FOLLOWS:
(1) The Commonwealth Office of Technology shall create an Artificial Intelligence Governance Committee to
govern the use of artificial intelligence systems by state departments, state agencies, and state administrative
bodies by:
(a) Developing policy standards and guiding principles to mitigate risks and protect data and privacy of
Kentucky citizens and businesses that adhere to the latest version of Standard ISO/IEC 42001 of the
International Organization for Standardization;
(b) Establishing technology standards to provide protocols and requirements for the use of generative
artificial intelligence and high-risk artificial intelligence systems;
(c) Ensuring transparency in the use of artificial intelligence systems;
(d) Maintaining a centralized registry to include current inventory of generative artificial intelligence
systems and high-risk artificial intelligence systems; and

CHAPTER 66 5
(e) Developing an approval process to include a registry of application, use case, and decision rationale
aimed at mitigation of risks.
(2) The Artificial Intelligence Governance Committee shall develop policies and procedures to ensure that any
department, program, cabinet, agency, or administrative body that utilizes and accesses the
Commonwealth's information technology and technology infrastructure shall:
(a) Verify the use and development of generative artificial intelligence systems and high-risk artificial
intelligence systems; and
(b) Act in compliance with responsible, ethical, and transparent procedures to implement the use of
artificial intelligence technologies by:
1. Ensuring artificial intelligence models have comprehensive and complete documentation that
is available for review and inspection;
2. Requiring review and intervention by humans dependent on the use case and potential risk for
all outcomes from generative and high-risk artificial intelligence systems; and
3. Ensuring the use of generative artificial intelligence and high-risk artificial intelligence
systems are resilient, accountable, and explainable.
(3) The Commonwealth Office of Technology shall prioritize personal privacy and the protection of the data of
individuals and businesses as the state develops, implements, employs, and procures artificial intelligence
systems, generative artificial intelligence systems, and high-risk artificial intelligence systems by ensuring
all departments, agencies, and administrative bodies:
(a) Allow only the use of necessary data in artificial intelligence systems;
(b) Do not allow unrestricted access to personal data controlled by the Commonwealth; and
(c) Secure all data and implement a timeframe for data retention.
(4) To maintain and secure the technology infrastructure, information technology, information resources, and
personal information, all departments, agencies, and administrative bodies shall be subject to review of
generative artificial intelligence systems or high-risk artificial intelligence systems.
(5) At a minimum, the executive director of the Commonwealth Office of Technology shall consider and
document:
(a) How the artificial intelligence system will not result in unlawful discrimination against any
individual or group of individuals;
(b) How the use of generative artificial intelligence or other artificial intelligence capabilities will benefit
the citizens of the Commonwealth and serve the objectives of the department or agency;
(c) To what extent oversight and human interaction of the artificial intelligence system should be
required;
(d) The potential risks, including cybersecurity, data protection and privacy, and health and safety of
individuals and businesses, and a mitigation strategy to any identified or potential risk; and
(e) The proper control and management for all data possessed by the Commonwealth to maintain
security and data quality.
(6) (a) A department, agency, or administrative body shall disclose to the public, through a clear and
conspicuous disclaimer, when generative artificial intelligence, artificial intelligence systems, or
other artificial intelligence-related capabilities are used:
1. To render any decision regarding individual citizens or businesses within the state;
2. In any process, or to produce materials used by the system or humans, to inform a decision or
create an output; or
3. To produce information or outputs accessible by citizens and businesses.
(b) When an artificial intelligence system makes external decisions related to citizens of the
Commonwealth, a department, agency, or administrative body shall:
Legislative Research Commission PDF Version

6 ACTS OF THE GENERAL ASSEMBLY
1. Disclose how artificial intelligence is used in the decision-making process;
2. Provide the extent of human involvement in validating and oversight of any decision made;
and
3. Make readily available options for individuals to appeal a consequential decision that involves
artificial intelligence.
(c) Any disclaimer under paragraph (a) of this subsection shall also provide information regarding
third-party artificial intelligence products or programs, including but not limited to information as to
how the high-risk artificial intelligence system or generative artificial intelligence system works, such
as system cards or other documented information provided by developers.
(7) The Commonwealth Office of Technology shall establish policies to encompass legal and ethical
frameworks to ensure that any artificial intelligence systems shall align with existing laws, administrative
regulations, and guidelines, which shall be updated at least annually to maintain compliance as technology
and industry best practices evolve.
(8) (a) Operating standards for utilization of high-risk artificial intelligence systems shall prohibit the use of
a high-risk artificial intelligence system to render a consequential decision without the design and
implementation of a risk management policy and program for high-risk artificial intelligence
systems. The risk management policy shall:
1. Specify principles, process, and personnel that shall be utilized to maintain the risk
management program; and
2. Identify, mitigate, and document any bias or potential bias that is a potential consequence of
use in making a consequential decision.
(b) Each risk management policy designed and implemented shall at a minimum adhere to the latest
version of Standard ISO/IEC 42001 of the International Organization for Standardization, or
another national or internationally recognized risk management framework for artificial intelligence
systems, and consider the:
1. Size and complexity of the deployer;
2. Nature, scope, and intended use of the high-risk artificial intelligence system and its deployer;
and
3. Sensitivity and volume of data processed.
(9) Sections 1 to 3 of this Act shall not be construed to require the disclosure of trade secrets, confidential or
proprietary information about the design or use of an artificial intelligence system, or any information
which would create a security risk.
(10) The Commonwealth Office of Technology shall provide education and training of employees about the
benefits and risks of artificial intelligence and allowable use policies.
(11) (a) The Commonwealth Office of Technology shall transmit reports to the Legislative Research
Commission and the Interim Joint Committee on State Government by December 1, 2025, and
annually every year thereafter. The reports shall include:
1. The artificial intelligence registry, which shall include the current inventory and use case of
artificial intelligence utilized in state government;
2. Applications received for use of artificial intelligence, including the decision and rationale in
approving or disapproving a request in compliance with subsection (5)(c) of this section; and
3. Third-party artificial intelligence developers, system administrators, providers, and contractors
submitted for review in compliance with subsection (5) of this section.
(b) To facilitate the report in paragraph (a) of this subsection, the Commonwealth Office of Technology
shall receive from each department, agency, and administrative body a report examining and
identifying potential use cases for the deployment of generative artificial intelligence systems and
high-risk artificial intelligence systems, including a description of the benefits and risks to
individuals, communities, government, and government employees.

CHAPTER 66 7
(12) The Commonwealth Office of Technology shall promulgate administrative regulations in accordance with
KRS Chapter 13A to implement this section and Section 2 of this Act by December 1, 2025.
Section 4. KRS 117.001 is amended to read as follows:
As used in this chapter[, unless the context otherwise requires]:
(1) "Audit log" means a detailed record of all actions and events that have occurred on the voting system,
including:
(a) Log-in attempts with username and time stamp;
(b) Election definition and setup;
(c) Ballot preparation and results processing;
(d) Diagnostics of any type; and
(e) Error and warning messages and operator response;
(2) "Automatic tabulating equipment" means apparatus necessary to automatically examine and count votes as
designated on ballots and data processing machines which can be used for counting ballots and tabulating
results;
(3) "Ballot" or "official ballot" means the official presentation of offices and candidates to be voted for, including
write-in candidates, and all public questions submitted for determination, and shall include a voting machine
ballot, a paper ballot, an absentee ballot, a federal provisional ballot, a federal provisional absentee ballot, or a
supplemental paper ballot which has been authorized for the use of voters in any primary, regular election, or
special election by the Secretary of State or the county clerk;
(4) "Ballot box" means any box, bag, or other container that can be locked, sealed, or otherwise rendered tamper-
resistant, for receiving ballots;
(5) "Ballot marking device" means any approved device for marking a ballot which will enable the ballot to be
tabulated manually or by means of automatic tabulating equipment;
(6) "Election" or "elections" means any primary, regular election, or special election;
(7) "Election officer" has the same meaning as in KRS 118.015;
(8) (a) "Electioneering communication" means any communication broadcast by cable, internet, television,
or radio, presented on an electronic billboard, made in telephone calls to personal residences, or
otherwise electronically distributed that:
1. Unambiguously refers to any candidate for any state, county, city, or district office, or to any
ballot measure;
2. Is broadcast, printed, mailed, delivered, made, or distributed within forty-five (45) days before
a primary or regular election; and
3. Is broadcast to, distributed to, in telephone calls made to, or otherwise distributed to an
audience that includes members of the electorate for such public office or the electorate
associated with the ballot containing the ballot measure.
(b) "Electioneering communication" does not include:
1. Any news articles, editorial endorsements, opinions or commentary, writings, or letters to the
editor printed in a newspaper, magazine, or other periodical not owned or controlled by a
candidate, committee, or political party;
2. Any editorial endorsements or opinions aired by a broadcast facility not owned or controlled
by a candidate, committee, or political party;
3. Any communication by persons made in the regular course and scope of their business or any
communication made by a membership organization solely to members of such an
organization and their families;
4. Any communication that refers to any candidate only as part of the popular name of a bill or
statute;
Legislative Research Commission PDF Version

8 ACTS OF THE GENERAL ASSEMBLY
5. A communication that constitutes a contribution or independent expenditure as defined in
KRS 121.015; or
6. A bona fide newscast, news interview, news documentary, or on-the-spot coverage of a bona
fide news event broadcast on any radio or television broadcasting station, including a cable or
satellite television operator, programmer, or producer, that is not owned or controlled by a
candidate, committee, or political party, provided that the entity does not remove or modify any
disclaimer provided by the sponsor of the communication;
(9) "E-poll book" means an electronic device capable of holding a file of voter data and related information for
use in identifying registered voters prior to a voter's receiving or casting a ballot, and allowing a voter to
electronically sign in on an electronic registered voter roster in lieu of signing a paper registered voter roster;
(10)[(9)] "Federal provisional voter" means a person:
(a) Who does not appear to be registered to vote;
(b) Whose name does not appear on the precinct roster;
(c) Who has not provided proof of identification to the precinct election officer before voting in a federal
election; and
(d) Who elects to proceed with voting a federal provisional ballot under KRS 117.229;
(11)[(10)] "Federal provisional ballot" or "federal provisional absentee ballot" means ballots which have been
authorized by the Secretary of State or the county clerk to be used by federal provisional voters in any federal
primary or election;
(12)[(11)] "Information content provider" means any person or entity that is responsible, in whole or in part,
for the creation or development of information provided through the internet or any other interactive
computer service;
(13) "Inner envelope" or "secrecy envelope" means the envelope provided to the voter with a ballot into which the
voter shall place his or her voted ballot;
(14) "Interactive computer service":
(a)_ Means any information service, system, or access software provider that provides or enables
computer access by multiple users to a computer server, including specifically a service or system
that provides access to the internet and such services offered or systems operated by libraries or
educational institutions; and
(b) Does not include exemptions in the Communication Decency Act of 1996, as amended, 47 U.S.C. sec.
230;
(15)[(12)] "Political group" has the same meaning as in KRS 118.015;
(16)[(13)] "Political organization" has the same meaning as in KRS 118.015;
(17)[(14)] "Precinct ballot counter" means an automatic tabulating device used at the precinct to tabulate and
process ballots;
(18)[(15)] "Proof of identification" means a document that was issued by:
(a) The United States or the Commonwealth of Kentucky, and the document contains:
1. The name of the individual to whom the document was issued; and
2. A photograph of the individual to whom the document was issued;
(b) The United States Department of Defense, a branch of the uniformed services, the Merchant Marine, or
the Kentucky National Guard, and the document contains:
1. The name of the individual to whom the document was issued; and
2. A photograph of the individual to whom the document was issued;
(c) A public or private college, university, or postgraduate technical or professional school located within
the United States, and the document contains:
1. The name of the individual to whom the document was issued; and

CHAPTER 66 9
2. A photograph of the individual to whom the document was issued; or
(d) Any city government, county government, urban-county government, charter county government,
consolidated local government, or unified local government, which is located within this state, and the
document contains:
1. The name of the individual to whom the document was issued; and
2. A photograph of the individual to whom the document was issued;
(19) "Sponsor" means the person or entity paying for the electioneering communication. If a person or entity
acts as an agent for another or is reimbursed by another for the payment, the original source of the
payment is the sponsor;
(20) (a) 1. "Synthetic media" means an audio recording or video recording of an identifiable natural
individual's appearance, action, or speech that has been intentionally manipulated with the
use of generative adversarial network techniques in a manner to create a realistic but false
audio or video that produces:
a. A depiction that, to a reasonable individual, is of an identifiable natural individual in
appearance, action, or speech that did not actually occur in reality and that was created
without the consent of such individual; and
b. A fundamentally different understanding or impression of the appearance, action, or
speech than a reasonable person would have from the unaltered, original version of the
audio recording or video recording.
2. As used in this paragraph:
a. "Generative adversarial network" means a machine learning model that uses neural
networks to develop new data and make more accurate predictions; and
b. "Neural network" means a machine learning algorithm modeled on the human brain
and nervous system.
(b) "Synthetic media" does not include content that contains a disclosure under subsection (1) of
Section 5 of this Act.
(21)[(16)] "Voting booth" or "ballot completion area" means an area in which a voter casts his or her vote or
completes his or her ballot which is designed to ensure the secrecy of the vote;
(22)[(17)] "Vote center" means a consolidated precinct of the county;
(23)[(18)] "Voting equipment" means any physical component of a voting system and includes voting machines
where voting machines are in operation;
(24)[(19)] "Voting machine" or "machine":
(a) Means a part of a voting system that consists of one (1) or more electronic devices that operate
independently or as a combination of a ballot marking device and an electronic or automatic vote
tabulation device; and
(b) Does not include an e-poll book;
(25)[(20)] "Voting system":
(a) Means the total combination of physical, mechanical, electromechanical, or electronic equipment,
including the software, hardware, firmware, and documentation required to program, control, and
support that equipment, that is used to:
1. Define ballots;
2. Cast and count votes;
3. Report or display election results; and
4. Maintain and produce any audit trail information;
(b) Includes the practices and associated documentation used to:
Legislative Research Commission PDF Version

10 ACTS OF THE GENERAL ASSEMBLY
1. Identify system components and versions of those components;
2. Test the system during its development and maintenance;
3. Maintain records of system errors and defects;
4. Determine specific system changes to be made to a system after the initial qualification of the
system;
5. Make available any materials to the voter, such as notices, instructions, forms, or paper ballots;
and
(c) Does not include an e-poll book; and
(26)[(21)] "Voter-verified paper audit trail" means a contemporaneous paper record of a ballot printed for the
voter to confirm his or her votes before the voter casts his or her ballot that:
(a) Allows the voter to verify the voter's ballot choices before the casting of the voter's ballot;
(b) Is not retained by the voter;
(c) Does not contain individual voter information;
(d) Is produced on paper that is sturdy, clean, and resistant to degradation; and
(e) Is readable in a manner that makes the voter's ballot choices obvious to the voter or any person without
the use of computer or electronic code.
SECTION 5. A NEW SECTION OF KRS CHAPTER 117 IS CREATED TO READ AS FOLLOWS:
(1) (a) Any candidate for any elected office whose appearance, action, or speech is altered through the use
of synthetic media in an electioneering communication may seek injunctive or other equitable relief
against the sponsor of the electioneering communication requiring that the communication includes
a disclosure that is clear and conspicuous and included in, or alongside and associated with, the
content in a manner that is likely to be noticed by the user.
(b) The court may award a prevailing party reasonable attorney's fees and costs. This paragraph does
not limit or preclude a plaintiff from securing or recovering any other available remedy.
(2) In any action brought under subsection (1) of this section:
(a) The plaintiff shall:
1. File in Circuit Court of the county in which he or she resides; and
2. Bear the burden of establishing the use of synthetic media by clear and convincing evidence.
(b) The following shall not be liable except as provided in subsection (3) of this section:
1. The medium disseminating the electioneering communication; and
2. An advertising sales representative of such medium.
(3) Failure to comply with an order of the court to include the required disclosure herein shall be subject to the
penalties set for KRS 121.990(3) for violation of KRS 121.190(1).
(4) It is an affirmative defense for any action brought under subsection (1) of this section that the
electioneering communication containing synthetic media includes a disclosure that is clear and
conspicuous and included in, or alongside and associated with, the content in a manner that is likely to be
noticed by the user.
(5) Except when a licensee, programmer, or operator of a federally licensed broadcasting station transmits an
electioneering communication that is subject to 47 U.S.C. sec. 315, a medium or its advertising sales
representative may be held liable in a cause of action brought under subsection (1) of this section if:
(a) The person intentionally removes any disclosure described in subsection (4) of this section from the
electioneering communication it disseminates and does not remove the electioneering
communication or replace the disclosure when notified; or
(b) Subject to affirmative defenses described in subsection (4) of this section, the person changes the
content of an electioneering communication in a manner that results in it qualifying as synthetic
media.

CHAPTER 66 11
(6) (a) A provider or user of an interactive computer service shall not be treated as the publisher or speaker
of any information provided by another information content provider.
(b) An interactive computer service may be held liable in accordance with subsection (3) of this section.
(c) An interactive computer service shall be exempt as provided by the Communications and Decency
Act of 1996, as amended, 47 U.S.C. sec. 230.
(7) Courts are encouraged to determine matters under this section expediently.
Section 6. Whereas implementing governance to maximize the opportunities for the responsible and
ethical use of artificial intelligence is vitally important to combat the critical impact artificial intelligence can have on
the security of data and information in the Commonwealth and it is critically important to protect candidates and
election officers from fraudulent misrepresentations of themselves and their issues, an emergency is declared to exist,
and this Act takes effect upon its passage and approval by the Governor or upon its otherwise becoming a law.
Signed by Governor March 24, 2025.
Legislative Research Commission PDF Version

[DELETED:  " " M i s s r h t g o i b n l t c D n i a a i s t i u f d a " " " " m a d a o a b t d o i a m a h a i s t i o p s l " " M c o p a r o d t a c i i a v o D " " a i s m a a i s o s t " " M D]
[DELETED:  " r m t p e a s t a d b " f m a t t a u t s i p a " " " p a e o a c d a a e b w a " " i m a c e s n s d T T P A D s s t t p i e p a t i o t D a i i n m p t e f P D A T T T T T T]
[DELETED:  T F a f a r i e t t o t C R a o l o c i t p a s f w s s p a s i a w t b g i a o r m p T e I i t r t p e a s i E C P a t b c a t a a e a t o t I c w o a e p i p s a m P O t d o a s g i p w i f t D f s e b a a c s f a m I E I P D E p m a i c p s a f t r e a t u o g a i G A C P T]
[DELETED:  P P a r i a w K C 1 n f t S r a c p f a s a f a l g S a a m b g g d b l a o o M A o t a p f o c o a d o o a t t P N R p t o s s b c s b s i N c b t s t t A a R C a t D f T A s b t o w o u o t e b o s d t p f y t r n t t C O o A A A T D E E M]
[DELETED:  D T p c a o a b t u a a t V A E R E t u o g a i a h a i T A D S T A a m t e d o t C O o T s c a H t a i s w n r i u d a a H T w e o a h i o t a i s s b T T p c a m f a d p b t C t m ( A d a o a b s d t t p t a c a d w g a i a i s o T I T W a a i s m e d r t c o t]
[DELETED:  D P M A d u p ( o t s s a p i r T C O o T s e p t e l a e ( O o a r m p a p f h a i S p p a p t s b u t m t r I E o S I 4 o t I O f S o S N S S T ( T C O o T s t r t t L R a t I J C o S G b D 1 2 a T A T T r f e d a a a b a r e a a i s i a d o t b a r t]
[DELETED:  T " l m a d r o a a a e t h o o t v s L E B D E " " " " " " ( " U I I b t d t i t c m t o o d t a t i m o t e f s p o o t e " A A A m b a m o s t m o s a A]
[DELETED:  A A " " W W W W " " t c o d o i p t t i o a o i " " M a i s s o a s p t p o e D " " " " T T A T T A A T]
[DELETED:  A A c g c g u g c c g T A " a a a f a o i r b a f t p t o s o t ( 1 " A A A " " " m d n i c t c a d u s ( o " " " " M a p o a v s t c o o ( o m e d t o D " M t t c o p m e o e e t s h f a d r t p c a D C R M I]
[DELETED:  I T M D M D " A I D I I ( A T I T F B T T A F I i a a d f a a b u s ( o t s t t c c s m i a d t i c a E c t i s t 4 U s 3 a m o i a s T c i d a d n r t e S]
[DELETED:  ( A A A C 6   W i g t m t o f r a]